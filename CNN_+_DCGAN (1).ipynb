{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN + DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcSLjD22QM1a"
      },
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.cifar10 import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras import datasets\n",
        "from matplotlib import pyplot\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "import PIL\n",
        "import glob\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "import seaborn as sns"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ-LaJ7_sqPz"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahCZmx9UtZMH"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd \n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7c-4vRfspPn"
      },
      "source": [
        "TMP_DATA_DIR = \"dataset/tmp\"\n",
        "TMP_LABELS_DIR = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Test\")\n",
        "\n",
        "TRAINING_DATA_DIR = \"dataset/training\"\n",
        "VALIDATION_DATA_DIR = \"dataset/validation\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x18lZmMJszQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234cd992-2b54-49c1-d7fc-0b33546c1ccf"
      },
      "source": [
        "#Fetch images deom GTSRB website\n",
        "#Images for training\n",
        "!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\n",
        "#Images for validation    \n",
        "!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_Images.zip\n",
        "#Labels for validation\n",
        "!curl -LOC - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Test_GT.zip"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** Resuming transfer from byte position 276294756\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "curl: (33) HTTP server doesn't seem to support byte ranges. Cannot resume.\n",
            "** Resuming transfer from byte position 88978620\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "curl: (33) HTTP server doesn't seem to support byte ranges. Cannot resume.\n",
            "** Resuming transfer from byte position 99620\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "curl: (33) HTTP server doesn't seem to support byte ranges. Cannot resume.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgTS34gJs10s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c4ef63-12d4-4064-dfc6-eaf3be7f43db"
      },
      "source": [
        "%%time\n",
        "to_unpack = [\n",
        "    (\"GTSRB_Final_Training_Images.zip\", TMP_DATA_DIR),\n",
        "    (\"GTSRB_Final_Test_Images.zip\", TMP_DATA_DIR),\n",
        "    (\"GTSRB_Final_Test_GT.zip\", TMP_LABELS_DIR)\n",
        "]\n",
        " \n",
        "for file, directory in to_unpack:\n",
        "    print(\"Unzipping {} to {}...\".format(file, directory))\n",
        "    with zipfile.ZipFile(file,\"r\") as zip_ref:\n",
        "        zip_ref.extractall(directory)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unzipping GTSRB_Final_Training_Images.zip to dataset/tmp...\n",
            "Unzipping GTSRB_Final_Test_Images.zip to dataset/tmp...\n",
            "Unzipping GTSRB_Final_Test_GT.zip to dataset/tmp/GTSRB/Final_Test...\n",
            "CPU times: user 7.42 s, sys: 2.99 s, total: 10.4 s\n",
            "Wall time: 16.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-iahiyRs6SK"
      },
      "source": [
        "# Collect all PPM files and their labels\n",
        "\n",
        "tmp_train_data_dir = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Training/Images\")\n",
        "\n",
        "# Get all subdirectories of data_dir. Each represents a label.\n",
        "directories = [d for d in os.listdir(tmp_train_data_dir) \n",
        "               if os.path.isdir(os.path.join(tmp_train_data_dir, d))]\n",
        "# Loop through the label directories and collect the data in two lists, labels and images.\n",
        "ppm_files_train = []\n",
        "ppm_labels_train = []\n",
        "for class_directory in directories:\n",
        "    label_dir = os.path.join(tmp_train_data_dir, class_directory)\n",
        "    file_names = [os.path.join(label_dir, f) \n",
        "                  for f in os.listdir(label_dir) if f.endswith(\".ppm\")]\n",
        "    # For each label, load it's images and add them to the images list.\n",
        "    # And add the label number (i.e. directory name) to the labels list.\n",
        "    for image_file in file_names:\n",
        "        ppm_files_train.append(image_file)\n",
        "        ppm_labels_train.append(class_directory)\n",
        "        \n",
        "# Let's have it sorted for better debugging.\n",
        "ppm_files_train.sort()\n",
        "ppm_labels_train.sort()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg9PGIfStC_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3684611d-7a1f-4e29-9ced-9f96ce8292fc"
      },
      "source": [
        "%%time\n",
        "# Convert\n",
        "# from: dataset/Final_Training/Images/00000/00000_00000.ppm\n",
        "# to:   dataset/training/00000/00000_00000.jpg\n",
        "\n",
        "for ppm_file, label in zip(ppm_files_train, ppm_labels_train):\n",
        "    image = Image.open(ppm_file)\n",
        "    directory = os.path.join(TRAINING_DATA_DIR, label)\n",
        "    image_filename = \"{}.jpg\".format(os.path.splitext(os.path.basename(ppm_file))[0])\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    \n",
        "    image.save(os.path.join(directory, image_filename))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.3 s, sys: 2.43 s, total: 12.7 s\n",
            "Wall time: 12.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk4YQUXMuj2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e8d630-8f4b-43d3-9dd7-2affc17be650"
      },
      "source": [
        "# Print all categories with example image for each of them.\n",
        "preprocessed_training_dirs = [d for d in os.listdir(TRAINING_DATA_DIR) \n",
        "               if os.path.isdir(os.path.join(TRAINING_DATA_DIR, d))]\n",
        "preprocessed_training_dirs.sort()\n",
        "\n",
        "train_images = []\n",
        "for training_dir in preprocessed_training_dirs:\n",
        "    train_images.append(os.path.join(TRAINING_DATA_DIR, training_dir, \"00000_00000.jpg\"))\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/256)\n",
        "image_data = image_generator.flow_from_directory(str(TRAINING_DATA_DIR), target_size=(32, 32))\n",
        "\n",
        "for image_batch, label_batch in image_data:\n",
        "  print(\"Image batch shape: \", image_batch.shape)\n",
        "  print(\"Label batch shape: \", label_batch.shape)\n",
        "  break"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 39209 images belonging to 43 classes.\n",
            "Image batch shape:  (32, 32, 32, 3)\n",
            "Label batch shape:  (32, 43)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZwINXFpvxLk"
      },
      "source": [
        "#Load testing set\n",
        "tmp_validation_data_dir = os.path.join(TMP_DATA_DIR, \"GTSRB/Final_Test/Images\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Nzv1gOv3Do",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f693d12e-5542-4b0a-8665-ab44d6b2f993"
      },
      "source": [
        "%%time\n",
        "\n",
        "tmp_validation_data_files = [f for f in os.listdir(tmp_validation_data_dir) if f.endswith(\".ppm\")]\n",
        "test_images = []\n",
        "\n",
        "#export as JPGs\n",
        "for ppm_file in tmp_validation_data_files:\n",
        "    image_dir = os.path.join(tmp_validation_data_dir, ppm_file) \n",
        "    image = Image.open(image_dir)\n",
        "    directory = VALIDATION_DATA_DIR\n",
        "    image_filename = \"{}.jpg\".format(os.path.splitext(os.path.basename(ppm_file))[0])\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "    final_image = os.path.join(directory, image_filename)\n",
        "    image.save(final_image)\n",
        "\n",
        "    test_images.append(final_image)\n",
        "    test_images.sort()\n",
        "    \n",
        "print(\"Validation images count:\", len(test_images))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation images count: 12630\n",
            "CPU times: user 5.49 s, sys: 863 ms, total: 6.35 s\n",
            "Wall time: 6.39 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcnikEfC4Z_p"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW5ErfCS5PDn"
      },
      "source": [
        "from skimage import color, exposure, transform\n",
        "from skimage import io\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def preprocess_img(img):\n",
        "    # Histogram normalization in v channel\n",
        "    hsv = color.rgb2hsv(img)\n",
        "    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
        "    img = color.hsv2rgb(hsv)\n",
        "\n",
        "    # central square crop\n",
        "    min_side = min(img.shape[:-1])\n",
        "    centre = img.shape[0] // 2, img.shape[1] // 2\n",
        "    img = img[centre[0] - min_side // 2:centre[0] + min_side // 2,\n",
        "              centre[1] - min_side // 2:centre[1] + min_side // 2,\n",
        "              :]\n",
        "\n",
        "    # rescale to standard size\n",
        "    img = transform.resize(img, (32, 32))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_class(img_path):\n",
        "    return int(img_path.split(os.sep)[-2])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdJyOJ2C4XTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20e1196-6995-47df-af2e-e3b68790f5ae"
      },
      "source": [
        "root_dir = 'dataset' + os.sep + 'training' + os.sep\n",
        "\n",
        "imgs = []\n",
        "labels = []\n",
        "\n",
        "all_img_paths = glob.glob(os.path.join(root_dir, '*/*.jpg'))\n",
        "\n",
        "np.random.shuffle(all_img_paths)\n",
        "for img_path in all_img_paths:\n",
        "    img = preprocess_img(mpimg.imread(img_path))\n",
        "    label = get_class(img_path)\n",
        "    imgs.append(img)\n",
        "    labels.append(label)\n",
        "\n",
        "X = np.array(imgs, dtype='float32')\n",
        "# Make one hot targets\n",
        "Y = np.eye(43, dtype='uint8')[labels]\n",
        "\n",
        "print(len(X))\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X = X / 255.0\n",
        "\n",
        "# Split data into training and validation (test) set\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "oHcvfWFjdzQm",
        "outputId": "188fa6d8-164a-4364-9faa-39f6b4c03290"
      },
      "source": [
        "print(len(train_images))\n",
        "image = train_images[100]\n",
        "\n",
        "pyplot.imshow(image[:, :, :]*255)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0d599e1cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOtOdWrdFpTv"
      },
      "source": [
        "# Generate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bd8v_vkFom0"
      },
      "source": [
        "# example of loading the generator model and generating images\n",
        "from keras.models import load_model\n",
        "from numpy.random import randn\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "  # generate points in the latent space\n",
        "  x_input = randn(latent_dim * n_samples)\n",
        "  # reshape into a batch of inputs for the network\n",
        "  x_input = x_input.reshape(n_samples, latent_dim)\n",
        "  return x_input\n",
        " \n",
        "\n",
        "# Load model\n",
        "generator = load_model('trained_generator_model.h5')\n",
        "# Generate latent points\n",
        "latent_points = generate_latent_points(100, 5000)\n",
        "# Generate images\n",
        "generated_images = generator.predict(latent_points)\n",
        "print(generated_images.shape)\n",
        "\n",
        "# Show generated data\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(generated_images[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeANjuj8E6tX"
      },
      "source": [
        "# Train CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0NPdkBcFbjU"
      },
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(43, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Test the model on the dataset\n",
        "history = model.fit(train_images, train_labels, epochs=50, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model: accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.title('CNN accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model: loss\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.title('CNN loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
        "\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEgkZZXk08q9"
      },
      "source": [
        "# Predict labels for generated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S819QCsA09Fg"
      },
      "source": [
        "# Predict labels of generated data\n",
        "predictions = model.predict(generated_images)\n",
        "print(predictions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJFiWYk4GR7F"
      },
      "source": [
        "# Show predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQnHISKzGrOX"
      },
      "source": [
        "labelNames = ['20 km/h', '30 km/h', '50 km/h', '60 km/h', '70 km/h', '80 km/h', '80 km/h end', '100 km/h', '120 km/h', 'No overtaking',\n",
        "               'No overtaking for tracks', 'Crossroad with secondary way', 'Main road', 'Give way', 'Stop', 'Road up', 'Road up for track', 'Brock',\n",
        "               'Other dangerous', 'Turn left', 'Turn right', 'Winding road', 'Hollow road', 'Slippery road', 'Narrowing road', 'Roadwork', 'Traffic light',\n",
        "               'Pedestrian', 'Children', 'Bike', 'Snow', 'Deer', 'End of the limits', 'Only right', 'Only left', 'Only straight', 'Only straight and right', \n",
        "               'Only straight and left', 'Take right', 'Take left', 'Circle crossroad', 'End of overtaking limit', 'End of overtaking limit for track']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zrx4LEOGReS"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(generated_images[i])\n",
        "    plt.xlabel(labelNames[np.argmax(predictions[i])] + ' (' + str(np.amax(predictions[i])) + ')')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci4SGkdFaVEj"
      },
      "source": [
        "# Remove uncertain images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br5YfAasabPN"
      },
      "source": [
        "print(train_images.shape)\n",
        "\n",
        "new_train_images = []\n",
        "new_train_labels = []\n",
        "\n",
        "for i, image in enumerate(generated_images):\n",
        "  # Get label predictions for generated image\n",
        "  prediction = predictions[i]\n",
        "  # Remove label with highest score\n",
        "  other_labels = np.delete(prediction, np.argmax(prediction)) \n",
        "\n",
        "  if np.sum(other_labels) == 0:\n",
        "    new_train_images.append(image)\n",
        "    new_train_labels.append(prediction)\n",
        "\n",
        "  # Stop when 4000 generated images are added\n",
        "  if len(new_train_images) == 4000:\n",
        "    break\n",
        "\n",
        "\n",
        "# Convert to numpy array\n",
        "new_train_images = np.array(new_train_images)\n",
        "new_train_labels = np.array(new_train_labels)\n",
        "\n",
        "# Combine old training set with generated training set\n",
        "extended_train_images = np.vstack([train_images, new_train_images])\n",
        "extended_train_labels = np.vstack([train_labels, new_train_labels])\n",
        "\n",
        "print(extended_train_images.shape)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQF4U2rLkx3T"
      },
      "source": [
        "# Test CNN with generated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm-X9DEmkyQV"
      },
      "source": [
        "# Create the new CNN model\n",
        "new_model = models.Sequential()\n",
        "new_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "new_model.add(layers.MaxPooling2D((2, 2)))\n",
        "new_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "new_model.add(layers.MaxPooling2D((2, 2)))\n",
        "new_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "new_model.add(layers.Flatten())\n",
        "new_model.add(layers.Dense(64, activation='relu'))\n",
        "new_model.add(layers.Dense(43, activation='softmax'))\n",
        "new_model.summary()\n",
        "\n",
        "# Compile and train the model\n",
        "new_model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Test the model on the dataset\n",
        "history = new_model.fit(extended_train_images, extended_train_labels, epochs=50, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model: accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.title('CNN + DCGAN accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model: loss\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.title('CNN + DCGAN loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}